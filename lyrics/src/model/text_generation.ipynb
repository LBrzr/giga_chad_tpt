{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t99z_4Kz7QjO"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcMy4H707QPQ"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skdpLi5NODhK"
      },
      "outputs": [],
      "source": [
        "from numpy import array, asarray\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWCfYNnSOIUs"
      },
      "source": [
        "load doc into memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NswqoZ3FOJ3K"
      },
      "outputs": [],
      "source": [
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r', encoding=\"utf-8\")\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTB8BvioOOqH"
      },
      "outputs": [],
      "source": [
        "# load\n",
        "# !dir\n",
        "in_filename = './usable_data.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dls-RVGdORIp"
      },
      "source": [
        "tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o3v1aTQOVLQ",
        "outputId": "27dc50f6-b4b2-436b-f68e-53cf37e32b1e"
      },
      "outputs": [],
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "print(type(sequences), type(sequences[0]), type(sequences[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB_qjU8-OXDs"
      },
      "outputs": [],
      "source": [
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wv0cg2vOZPZ"
      },
      "source": [
        "Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StnBJGEjOci2",
        "outputId": "e0b1c2cd-f050-4dd9-e6b8-74da48a29965"
      },
      "outputs": [],
      "source": [
        "# separate into input and output\n",
        "# sequences = array(sequences)\n",
        "X, y = sequences[:][:-1], sequences[:][-1]\n",
        "# X = sequences[:][:-1]\n",
        "# y = sequences[:][-1]\n",
        "# X = [ l[:-1] if len(l) != 0 else 0 for l in sequences]\n",
        "# y = [ l[-1] if len(l) != 0 else 0 for l in sequences]\n",
        "\n",
        "# X = array(X, dtype=object)\n",
        "# y = array(y)\n",
        "# print(X)\n",
        "# print(y)\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = 50 # X.shape[1]\n",
        "# print(seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvDxe-bnOfe4"
      },
      "source": [
        "Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40A1GIR8Ogkw",
        "outputId": "51bde4dd-972d-4c34-9292-b8d62b80901b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 50, 50)            1518600   \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 50, 100)           60400     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 30372)             3067572   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,737,072\n",
            "Trainable params: 4,737,072\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pBXxrl-OihD"
      },
      "source": [
        "compile model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Cgou_ID5OmVK"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjvgR7fnTlAt",
        "outputId": "fb5ca1f8-bc88-4ec2-cb8c-79fdd53d5127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, 50) <dtype: 'float32'>\n",
            "(None, 30372) <dtype: 'float32'>\n",
            "embedding_2 (None, 50) float32\n",
            "lstm_4 (None, 50, 50) float32\n",
            "lstm_5 (None, 50, 100) float32\n",
            "dense_4 (None, 100) float32\n",
            "dense_5 (None, 100) float32\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[print(i.shape, i.dtype) for i in model.inputs]\n",
        "[print(o.shape, o.dtype) for o in model.outputs]\n",
        "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owE_9DqgOnOe"
      },
      "source": [
        "Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "x8l5BroiOo_l"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'int\\'>\"})', \"(<class 'list'> containing values of types set())\"}), <class 'tensorflow.python.framework.ops.EagerTensor'>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# print(X.shape)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# re_x = array(X)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, tf\u001b[39m.\u001b[39;49mconvert_to_tensor(y, dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mfloat64), batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Dev\\Projects\\Courses\\IA\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Dev\\Projects\\Courses\\IA\\.venv\\lib\\site-packages\\keras\\engine\\data_adapter.py:1081\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1078\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m   1079\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m   1080\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1082\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1083\u001b[0m             _type_name(x), _type_name(y)\n\u001b[0;32m   1084\u001b[0m         )\n\u001b[0;32m   1085\u001b[0m     )\n\u001b[0;32m   1086\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1087\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1088\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[0;32m   1091\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'int\\'>\"})', \"(<class 'list'> containing values of types set())\"}), <class 'tensorflow.python.framework.ops.EagerTensor'>"
          ]
        }
      ],
      "source": [
        "# print(X.shape)\n",
        "# re_x = array(X)\n",
        "model.fit(X, tf.convert_to_tensor(y, dtype=tf.float64), batch_size=128, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtXe7oqmOtHN"
      },
      "source": [
        "save the model to file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbjNaYznOvju"
      },
      "outputs": [],
      "source": [
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7dPhrCeOxhe"
      },
      "source": [
        "save the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "7j56kSg27PbF",
        "outputId": "7df5e401-bb50-4558-cc5b-172671a43768"
      },
      "outputs": [],
      "source": [
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
